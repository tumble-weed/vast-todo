=========================================
- why did point cloud inversion fail
=========================================
- gaussian processes with a multi scale kernel 
=========================================
- class transitions
- 3d inversion
    - bending wires into shapes: use the spherical harmonics to model the contours of mnist digits. ( like 1,5. those with holes will not work)
=========================================
- information theoretic clustering
    . how do lstms induce stop signal
    . use gan for image quality
    . a model that converts lstm bits to an image
=========================================
Adversarial Examples
    - adversarial phenomenon: where i create adversarial examples from random noise
    - innocuous noise:
        keep adding noise to the network, then bring the features back to the reference. what remains in the noise will be innocuous. iteratively do this till a certain l2 distance away from the reference feature. 
            it might just add values to the edges to enhance them.
                non noisy areas will be important, i.e. it can give attribution
=========================================
GANS:
    - gan duck sliding
        is this even needed? why cant i just visualize the discriminator output on the entire input? the minima of it will be the locations where the points slide to.
            but if you give points according to their probabilities, then you can get the probs of the input space, someting that we normally dont associate with GANs --> its like prb(gt) * disc(importance)
    - why does singan collapse
=========================================
Feature Inversion:
    if you invert a classifier, it will give something that scores highly on a detector'sclassification but the bounding box will too big
        - you have previously put a loss on gradcam's attribution, but this has led to images without all the parts
            is there a way to find out which parts are there in an image?
    inverting random networks to observe effect of initialization
        PPR: Understanding deep representations through random weights
        PPR: A Powerful Generative Model Using Random Weights for the Deep Image Representation
    inpainting using CNN?
    inversion till a feature layer. 
        how do you measure distances? is a simple l2 distance between the features enough. but if a layer has more dimensions should it not lead to a larger distances on average?
        can a later layer have larger difference in L2 distance when an earlier layer has reduced its distance?
    maximally different at layer l-1 while the same at layer l
        will give the boundaries of a representation? --> how much can you tax the network before it goes out of the bucket
    "objects are liquid" look at the design of yolo to see how it learns location
=========================================
- inverting to learn important patches that can be arranged in the manner of GPNN: this is like positive factorization. why would such patches be useful at all? would they give class indicative terms, or would they make the images less realistic? 
    probably would make then unrealistic, the patches could be hierarchical which are resized at various scales? is this a better way of doing what i wanted to do in the gaussian pyramid paper? is this a way to reduce the adversarial phenomenon without having to resort to smoothness?

- relation between attribution and visualization
- relation between attribution and gradient descent
=========================================
- generative attribution method
    why are you trying to connect attribution and generation. generation is the next step, if you ask where then you can also ask about what exactly is there that you are interested in. like a verification.
        so is it like a focused learning? will you learn the features of the place you are looking at?
=========================================
- separating multiple objects vs general objectness
- inverting random cnns and transformers to observe inductive biases
- class agnostic saliency. if you didnt know which classes were in the image.
=========================================
Multithresholded Saliency
    - what are the things you cannot answer using attribution
    - https://distill.pub/2020/attribution-baselines/?utm_source=researcher_app&utm_medium=referral&utm_campaign=RESR_MRKT_Researcher_inbound
    - gradcam of arbitrary losses( like self saliency)
    - interpolating between faces using a single mask
    - accentuating the difference between 2 neural networks ( 1 mask, start from where they disagree the most )
    - how does the saliency change with dropout
    ...............................
    - gan discriminator longitudnal saliency, for a GAN which part of the image is important to the Discriminator early on, later on in the training?
    ...............................
    - "gradient based saliency is more flexible allowing for measuring saliency of arbitary losses"
        - where does this loss attend to ? ( e.g. focal loss), do we need ||dloss/dx|| ?
            the gradients of the loss are most influenced with "this" area in the image. gradvit
    - is the network seeing that object or some other object? --> feature deviation (fg --> fg +bg) 
        what about feature differences? ref_feat - fg_feat = bg_feat?
    - longitudnal visualization ( across the training run)
        - think this has already been done
    - can you improve the performance of vgg16 by masking its images by the attribution of resnet50?
        - has this been done?
    - both games with imposition that fg_feat + bg_feat = ref_feat?
    - maximizing the norm of the features? 
    - longitudnal between vgg with batch norm and without
- crossing the divide between explanation and segmentation
    - superpixel based saliency
        . different from igos as it will use cluster centers
        . different from igos as uses features
        . look at XAI?
        . why do it insitu with the optimization when you can pre-create superpixels?
    - what is the implication of the insertion and deletion game?
    .................................
    - ranking based loss
    - cosaliency of the same object between 2 images
    
=========================================
FLUKE:
    - learning to interpolate
=========================================
READ:
    the wavelet method forexplanation: waveletx
=========================================
