generate image in the style of another image
what is pixel perfect
adapter
extension
model
what does controlnet segmentation do to the generation?

txt2img can be used with controlnet to add the effect of an image

CFG scale: Classifier Free Guidance scale is a parameter to control how much the model should respect your prompt.

1 – Mostly ignore your prompt.
3 – Be more creative.
7 – A good balance between following the prompt and freedom.
15 – Adhere more to the prompt.
30 – Strictly follow the prompt.


what is the mask in controlnet
https://github.com/Mikubill/sd-webui-controlnet/discussions/434


can i use reference or adain to multiply the gem area?
can i use depth segmentation to acquire the text area?
controlnet tiling to replicate the diamond area?
controlnet outpainting to replicate the diamond area?
better textual inversion for the given image?

use this idea:
get the bgsubtraction of the styled image
get the style from it
somehow tile the style
get the mask from the text image
multiply it by the style...
pass it to the refinement module

USEFUL LINKS:
https://medium.com/the-research-nest/how-to-create-fancy-artistic-text-effects-using-stable-diffusion-1857169f8c5d
https://stable-diffusion-art.com/text-effect/
>3 methods to upscale images in Stable Diffusion (ControlNet tile upscale, SD upscale, AI upscale)
    COntrolnet tile upscale

Interrogator https://github.com/pharmapsychotic/clip-interrogator/blob/main/clip_interrogator/clip_interrogator.py
TO SEARCH:
how torun interrogator ( so that you can upscale)

CONCEPTS:
what is deepspeed, bitsandbytes, accelerate, safetensors
torch autocast
CONTROLNET MODELS
https://huggingface.co/lllyasviel/sd_control_collection/tree/main

