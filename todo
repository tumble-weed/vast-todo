1>TODO: 
- rerun sanity with xavier,
- GP saliency doesnt work!
- CAMERAS to attribution benchmark
- how to modify a run file to add more stuff?
- how many RUNS: elp 2,elp_with_scales_normalized 2,gp 2,with gp 2, unweighted 2,multiple seeds 3,3,3 = 16
<<LATEX>>
- create 'older versions' and identify which images are needed.
- check if we have all the images for the pipeline image
- more results: sanity, per class, stochasticity, window selection density
- erick pipeline diagram
- run on other methods shown in the elp paper (grad_cam etc) 8 methods: EP
- keep an eye out for negative correlation 
--------------------------------------------------------------------------
    6>DELETION
    - deletion game
    - metricsdatahandler
    - elp masking to deletion
    - we will havetorerun deletion on all methods on2 datasets and 2 arch
    - average across percentages or not in deletion? YES to keep it consistent across number of thresholds, it should be average? should be in icdmpaper
    - ( pmasked -p) or (p - pmasked): we did see negative scores -> we take difference (was that for deletion?). - should also store areas in deletion
    - average deletion
    - separate insertion and deletion percentages
    - what were the percentages for gpnn deletion evaluation, or do i run everything again?
--------------------------------------------------------------------------
        - MULTI:sharpness annealing
        - svhn in torchray. run pointing. find pretrained
        - finish deletion
        - mnist for detection or small datasets for detection. 
        - cifar in torchray. dont run pointing
        - deletion and insertion game in optimization
        - from igospape: ebp, mp,ep, gradcam,rise, integrated grads
        - ABLATIONS: number of thresholds, elp based masking, and my masking?
        - run all evaluations on compiled models!
        - run everything vgg_bn?
---------------------------------------------------------------------------
PAPER LINKS
- ijcai primary seconday, abstract
- https://cmt3.research.microsoft.com/IJCAI2024/Submission/Index#
- IJCNN
https://edas.info/N31614?c=31614
https://edas.info/newPaper.php?c=31628&track=120748
--------------------------------------------------------------------------
<<DOING>>
- rerun on the image in adebayo
- run multiple rng of methods ( extremal +gp, extremal-unweighted, extremal-simple)
- summarize gp saliency ( was it really 70%)
-------------------------------------------------------------------------
2>DONE:
- sanity fails completely for elp-gp, when it should fail "slowly"
- SESS
- DONE gradient 2, guided 2, grad cam 2,rise 2
- add vgg16_bn option to torchray
- check if vgg16_bn is available via pytorch
- add imagenet citation to experiments: elp with scales does not run any imagenet experiments
- decide if you want to use vgg_16bn or not?
-  remove coco
- push latex to github, pull into overleaf and compile
- check if libracam model results compatible with torchray
- add vast money
- rerun gradcam from unaltered torchray: resnet 90.1, vgg 86.5, this is the same fro my torchray, indicating some variatin
- commit everything in 112b before shifting
- pause only if certain debugging flags are set
- make a workflow file for the steps required
- automatically creatae a folder with the image whose attribution we require and attributions produced by all methods
- rclone scripts for syncing to remote
- run elp+gp on 117,118
- correct all resutls
- rerun gradcam on initial
- run summary on finished results: it is still giving same answer for difficult and non difficult: !might mess things up --> run it on the cheapest method (gradcam)
- create done lists
- create new 114,116 scripts to run the same metod in parallel
- add download to setup 
- compare results with compiled model
- check methodname for save?
- check if the visualizers are working correctly: gp, unweighted
- remove axis from scatter plot
- fix opencv error  apt-get update && apt-get install ffmpeg libsm6 libxext6  -y
- generate sanity for extremal perturbation
- lsxz,readxz
- spearman rank corr on rise data
- check_n_done
- message saumya
- run method on a chosen list of imroots
- see if gradcam and rise results can be read by explore_results
- elp convert download scripts to python: create alias
- try moving to second vast system
- elp run-scripts
- function to check all uploads to a host: write a bash function that takes an identifier string called instance_name as input and then echos it
- script to login to all instances and check their tmux sessions
- in generate scripts add save_detailed_results
- after backup kill 112b
- instead of running per method, meker per instance files
- check benchmark,and deterministic
- generate run scrips for elp 50 , and run
- jupyter password not workin: restarting workds
- code server password not working: fixed by copying config yaml
- vast copy syntax
- add insertion t deletion
- deletion getmodel etc
- vast upload benchmark directory
- how to send instance info 
- upload vutils
- deletion inference mode
- gp saliency
- gp saliency gradient based
- gp saliency meshgrid
- check if weights are normalized correctly in normalized
- verify unw and normalized samplers produce same traces
- verify effect of rng patchsampler
- vim utoindent
- rclone scripts for downloading cam-benchmark stuff 
- rclone scripts foruploading torchray
- install rclone
- dutils hack early loop
- dutils glob
- get_model
- cam_benchmark read imagenet
- imagenet 5000
- get_dataset
- get_transform
- dataset.images in continue
- imagenet localization parser: https://github.com/tumble-weed/GPNN-CAM/blob/1e1801b4a61e288971180a7102687efaf805a1b4/imagenet_localization_parser.py
- kill third machine before sleeping
- use_donefilelist
- continue filelist
- fileorder
- rng
- remove keys from vutils
- computation of point in variants vs attribution-benchmark
- return from extremal_perturbation
- compiled model in attribution_benchmark
- check if continue works when start,end and some images are present
- add file name to dutils hack, note
- continue_ start and end
- pascal class images etc in torchray
- add tensor_to_numpy to dutils
- who copies the git aliases
- perturbation to opts
- create environment
- install dutils
conda clean --all
- dutils:
scikit-image
matplotlib
ipdb
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
--------------------------------------------------------------------------
7>CHATGPT
- vim_and_commit: write a bash function vim_and_commit that takes a filename as input, cd into the containing directory for that file, opens the file with vim. upon closing, it adds and commits the file using the basename of the file as the commit message.
- python: given a module name modulename, import it from a directory called wrappers_for_torchray if a file called f"{modulename}.py" exists in wrappers_for_torchray
- subclass ipdb so that set_trace can take an enabled flag and an environment variable name. if the enabled flag is true or the environment variable is set the breakpoint is set
- how to unload an alias
- multiple copy buffers in vim
------------------------------------------------------------------------
4>LATER:
- fuzzy https://stackoverflow.com/questions/9439121/fuzzy-file-search-in-linux-console
- reload in dutils
- tight in dutils img_save
- run imagenet on elp paper methods (!might not be better than eelp)
- cam-benchmark
- visualize results for multiple methods ( cherry picking code?) (explore results) -- lowest sum of pointing
- after
- wrappers for benchmark in torchray
- training cifar and mnist, emnist networks
- reading gpnn attribution files and running deletion metric on them 

- window sampling density
- mask history

- write about spearman corr/read up on it
- vim syntax highlighting
- cifar and minst in torchray
- $VUTILS
- equalized sampling
- elp scripts
- elp vast-scripts
- copy download voc to cam_benchmark as well
- coco class images in torchray
- add as_class_names etc to coco
.......................................
- add scripts for rclone
.......................................
- list files in directory using git
- copy git files to gdrive
- copy files at frequent interval
- make service to list all directories with .git in them and copy those files

-------------------------------------------------------------------------
3>RECHECK:
- check if self-citation + no citation errors.
- check running

- automatically create table from finished results

- sumarize all methods
- imagenet results
>> Errors
- resize for imagenet
- correct extremal variants
>> Backend
- run_on_single_image_backend: should be to choose the image, while keeping the front end clean. should go through variants rather than directly calling oct17
- variants
- replace oct17 by variants in run_on_image2
- run_on_single_image 2
- where to attach visualizer ( in run_image file)
>> Others
- onstart vast-utils in workspace and final vast-utils
- copy stuff to vast-112-original
#- visualize attribution at the end of elp
#- visualize some crops
#- hack for visualization
#- sampling density for gaussian process windows
#- visualiz gp scatter
#- visualize gp modeled prob

- verify effect of rng gpsampler
- vmin and vmax in dutils
>> Rank Corr
- save sanity checks and rankcorr to metrics dir
- why is rank corr negative: check when running on multiple seeds
- load results according to explore_results for spearman
- spearman correlation
>> Sanity
- sanity checks
- generate sanity of gp
- run sanity

- load saved results using results data handler
- center did not get saved
- move results datahandler to cam-benchmark <only after you've figured out loading of results etc..>
- rng in savename
- crop sampling: limits should be int or floor or ceil?
>> Multi
- replace areas_torch with areas_scipy everywhere
- multi save
- wrapper for multi


- summary
- correct classes of saved resutls
- elp convert upload scripts to python
- patch_sampler
- create run scripts
-_oct17
- explore results
- change location of compiled in multithresh
- resultsdatahandler
- add optional saving to attribution_benchmark
- fix voc error
- download pascal dataset
- cam_benchmark models
- librecam models
- saver
- change tracker
- abspath in dutils
- 3 step softmax fixed window sizes
- init_mask_logit_mag
------------------------------------------------------------------------
5>MAYBE:
- visualize multi max of smooth and gradient side by side
------------------------------------------------------------------------
7>DANGERS:
gp saliency ight be bettwer
unw or normalized miht be better
elp-gp might not show improvements
the correlation might not be high enough
