- run gradient and guided again (runallsmaller, summarize_all_deletion, plotalldeletion)
- run road metric (summarize all road, out filename, plot )
#======================================================
- mnist insertion resnet8-relu road
- for road deletion, not all results might be in results2.. in that case to rerun it will need to combine them
    seems integrated gradients is not it results2
    all the resnet8_relu results will be inresults2, which is correct
    check if any overlap of directories between results2 and results
    in results/old_multi_results and results keep the latest of the files
        rsync changes the time stamp of the copy! because of probably the -ru and not the archive mode
    what does multithresh_saliency represent? is it the one whose results are in the paper or is it the previous version?
        it should be gametype both and what is the window size?
    if you visualize the saliencies ofboth vgg16 and resnet8_relu of the same image it can give an idea of the window size etc
        are the previous results wrong or are the metrics wrong or is the reading of the metrics wrong?
            metrics: collect can be wrong or createdeletion can be wrong
        vim debug grad_cam?
- move create_deletion_table from metrics to torchray/helpers or someplace else
- generate all road scores with new deletino thresholding
- after runrelu -> runroad (workondeletionroad8relu (run on mnist)) -> collectresults (summarize_all_deletion_road_small,summarize_all_deletion_road_resnet8relu) -> create table (createtable?) -> create graph (plotallroaddeletionforpaper)-> copy table to latex, create image from graph -> delete other instances --> transfer friles from 3090 instance to new instnce
- recheck experiments and conclusion
#GUIDED and GRAD
all guided experiments are wrong due to CELU units. we need to rerun on resnet8-relu by replacing CELU with RELU
#FACE TRANSITION
- face alignment and walking:
    https://github.com/1adrianb/face-alignment/blob/master/examples/demo.ipynb
    transforming the aligned faces:
        https://www.perplexity.ai/search/how-do-i-6c0YUKmxSYyuXBvzuJWUPQ?s=c#0a5f3c9a-ce0d-452a-8102-5d1f04b1a3d4
    ....................................
    laplacian blending? 
        is it in cnn_utils? use FINDPY
        from elp_masking import get_masked_input,DELETE_VARIANT,PRESERVE_VARIANT,laplacian_pyramid_blending
        masked = laplacian_pyramid_blending(x_, ref, multi_mask.detach() + 0*multi_mask, num_levels=6)
    ....................................
    facenet pytorch for identity
    dataset
    https://www.researchgate.net/publication/353682085_Is_Face_Recognition_with_Masks_Possible
    https://www.kaggle.com/datasets/hereisburak/pins-face-recognition
# BOTH
- see results of imagenet-5000 on game_type both
    both seems to give diffuse results as opposed to insertion, which gives sharper results. 
        issue with implementation or loss convergence?
# DISTILLATION
- faster convergence of distillation when using saliency? (compare yours with gradcam and maybe guided backprop)
    - run the knowledge-distillation-pytorch code
    - check how to create a curriculum
        . could be the starting mask where the object is just detected.
            . need a paired data loader that combines the masks and image
                . then also load the deletion data. use the percentage where the class is maximum?
<<EXPERIMENT/CODE>>
- ABLATION number of masks?
    add inner parser arguments
    run on cifar-10,cifar-100,mnist with 40,10 masks
    ......................................................
    - show self saliency comparion with elp:
        PYTHON look at elp code to add the feature layer. --> you can show it with a single area that doesnt change at all ( for imagenet)
            vimelp
            get the results out and save it with your chosen folder
            run_self_saliency
    - summarize rise
        summarize... in vimtmpalias
        python torchray/helpers/summary2.py --start --method rise_use_compiled_model --dataset voc_2007 --arch vgg16
    - run all methods on imagenet:
        scorecam, groupcam, grad_cam, elp, igospp, multi !guided-Ig
            how do you want to run this, using genrunscript? yeah wecan create genrunscripts for these
                cdrunjson, cp file, genrunscript, cdrunscript ; runtorchray 

    - add hash of the saliencies to the results
    CHATGPT, ERC: howto get hash of a numpy array in python 
<<READ/BROWSER>>
weak paper that might be interesting on how to write:
https://papers.bmvc2023.org/0188.pdf
gradient is still the same as guided backprop. why?
    it is different for resnet 50 in elp paper. so should be different for us as well. its odd it 
    https://www.codingninjas.com/studio/library/guided-backpropagation
    https://arxiv.org/abs/1412.6806
    
    run readpkl on guided and grad which have the same number in the table. compare what the saliencies look like:
        errors could be in arguments to saliency,running saliency, saving results, calculating metric, saving metric, running collect, making json from collect
Guided IG
- relation to "Xrai: region importance" and guided backprop
<<TIKZ>>
- evolution of the masks along side the concavity graph? TIKZ, ERC
- convert the graphs from single line to 2 lines LATEX ERC
- use tikz to recreate diagrams TIKZ,ERC
    the arrangement of the masks of ig vs multi
    the qualitative results
<<LATEX>>
- fix small dataset table to fit into area LATEX, ERC
- add accuracy of small networks to the headings in the table? LATEX,ERC
- argmin LATEX,ERC
- overlay concave graph beside text
- why are the references not loading LATEX ERC
<<DIAGNOSE>>
- mask sharpness as a function of the threshold ( should be hump like as well i believe )
    - should we reintroduce the sharpness loss?
- automatic object sizes by finding peak of concave approximation?
    - try this without the approximation? 
a why does it fail with mnist insertion
- better example for a concave graph
- better example for igos vs multi masking ( more detailed i think)
    make the links between images from folder to the paper folder
<<<WRITE>>>
- title
Approach
    - PPR: softmax operator details?
        psuedocode/python
    - PPR: softmax window, kernel size, blurring sigma
    - mention no auxiliary loss in aprroach
        PPR: approach
    - formalize compositional paths etc. create diagram for those
        WRITE
# NOT DOING
- figure igos?
#========================================================
# RECHECK
- captions
- locations of images
- typos, figure captions again, look at figures
- spaces under equations
- lots of repetition involving insertion game
- margin of the deletion table
- approach is lucid?
- masking operator
PPR how tofind the threshold
#======================================================== 
# MAYBE
- qualitative add green borderfor MTS
#======================================================== 
# DONE
- cnn utils fixed drop out mask
    PYTHON replace Dropout with FixedDropout. it has a sample_mask,unset mask setting. in eval it keeps this mask. in train it keeps sampling masks.
- gradcam on compiled model (torchray)
    . currently  backward "second time" error

- imagenet-both failed due to syntax error.
    change the run_json

- some more lines in applying the mask ( blur levels)
- reference for cifar-resnet implementation
- run cosaliency on an image and its flip
mention difference between deletion game during eval and opt
- conclusion
- mask operator as Mask
- fig:enter-label
- self-saliency iamges + section
- change table to resnet | vgg
- mention MTS
- remove mention of deletion
- deletion game reference
a,b,c,d in figures
multithresholded saliency to multi-thresholded
masking comparison example is bad
tma t-summarizedeletion
    summarize road all multi
    plotallroaddeletion
- MTS (ours)
- run road on all multi methods
- references
- table names
- MST to MTS
- restructure masking figure
- get names of layers from undederstanding...sanity check
fc8 fc7 fc6
- plot all thicker lines, 
    larger font sizes
    dont draw axis, 
    background color

- make images for the paper:
    masking
- push multi paper to github and then pull into overleaf
    graphs + legend
    comparison on imagenet
        . local cdpaper..
        . get classnames
        . how many? (3 or 4?)
        soup bowl: 809
        carton:478
        abacus 398
        cradle 516
        pitcher 725
        PICKUP TRUCK 717
- find the accuracies of the networks involved collect deletion?
    validate ...?
        workonvalidatevgg16
        workonvalidateresnet8
        /root/bigfiles/other/metrics-torchray/resnet8_performance
        /root/bigfiles/other/metrics-torchray/vgg16_performance
- make table in the paper
    summarize_all_deletion_smaller
    /root/evaluate-saliency-4/elp_with_scales/torchray/helpers/summarize_deletion.py

#======================================================== 
RUN JUST MULTI
 cdelp; python -m ipdb -c c examples/attribution_benchmark.py --arch vgg16 --dataset cifar-10 --save_detailed_results true --metrics deletion_game $continue_ --use_landataloader false --method multithresh_saliency --window_size 11 --save_results false
- erc upwork
workoncomparemasking
- instead of imagenet-5000 mention imagenet
- the figures for the paper
vim /root/bigfiles/other/metrics-torchray/where_elp_gp_beter_anchor_extremal_perturbation_with_simple_scale_and_crop_with_gp_gp_y_modelog_prob_gp_ncrops1100_gp_sample1_freq1_arch_vgg16_imroots_and_class_ids
# guided resnet8 cifar-10
# cifar-10-guided_backprop-resnet8
  0%|                                                                                                                 | 0/10000 [00:00<?, ?it/s]
- run just insertion
cdelp; python examples/attribution_benchmark.py --arch vgg16 --dataset cifar-10 --save_detailed_results true --metrics deletion_game $continue_ --use_landataloader true --method multithresh_saliency --window_size 3
 - just insertion game?
 - plotdeletion
 - summarize all deletion for multithresh saliency:
    methods=multithresh_saliency summarize_all_deletion_small
 - DATASET=mnist summarize_all_deletion
 - DATASET=cifar-10 IGNORE_METHOD=multithresh_saliency summarize_all_deletion
 - which image to run self saliency on 
 - self saliency panel: add imroot to savename
 - jet map without matplotlib axis for saving in saver
 - lr might be too high for self saliency on lower layers
 - vimtmpalias visualize get images using pointing game ( cherry pick )
 - vimtmpalias visualize qualitative for vgg16 and resnet50
 - visualize script in multithresh_saliency schedule of a randomly initialized mask vs a fully optimized one.
 - measure the mask area across images? -- why, this is not equivalent to elp area .. to show that elp's fixed area is not the way to go
 - collect results of all deletion scores ( summarize deletion? \& collect deletion)
---------------------------------------------------------------------
run in tmux
run multi imagenet  resnet50
IGNORE_METHOD=multithresh_saliency runallsmaller vgg16 mnist
run smaller:
    vgg16:
        cifar-10:
            multi
        cifar-100:
            guided
            grad_cam
            multi
        mnist:
            multi
     resnet8:
        cifar-10:
        cifar-100:
            multi
        mnist:
            multi
............................................         
        mnist:
            gradient
            guided
            grad_cam
            integrated
        cifar-10:
             gradient
            guided
            grad_cam
            integrated
         cifar-100:
             gradient
            integrated
      

######################################################################
######################################################################
DOING
- DROPOUT run for 3 dropouts on each layer
    run across the layers
---------------------------------------------------------------------
finish runs for all cifar stuff
t-smaller
runallsmaller
######################################################################
######################################################################
DONE:
 - the max point seems to be on the top left corner
 - gradcam doesnt seem to have saliency
 tmux sessions:
    - smaller: mnist resnet8
    - ?: c100 resnet8
    x smaller2: cifar-100 vgg16
    - smaller-vgg16 mnist vgg16
    - smaller-vgg16-c10 c10 vgg16
    - smaller-vgg16-c100 c100 vgg16

 - run in another vast instance:
    fix the issues with the vast-utils install
    setup an alias
    add money
    setup_instance
    run the program
 - see the ratios in collect

 cdrunjson &&  cp run_imagenet_vgg16.json run_smaller_vgg16.json && vim run_smaller_vgg16.json && genrunscript run_smaller_vgg16.json
 - check_git
 - check_rclone
 - save the ratios in summarize_deletion
Imagenet on competing is done i think
we should be running pointing on all the imagenet runs
---------------------------------------------------------------------
runallsmallervgg16:
    type expand alias to another variable and run
        in tmux
runallsmallerresnet8:
    in tmux
---------------------------------------------------------------------
visualize for multi paper?
    visualize the trajectory of the images ... 
    look at vimmulti (type vimmulti)
    look at how elp_massking is used and how the areas have been used 
    vim -O $multi -O $comparemasking
check n_done for imagenet vgg16,resnet50 
- which methods ( copy from vimrunjson run_imagenet_vgg16.json)
- loop overmethods and print
- print out the methodnames



NOT DOING
 - block diagram
 - final saliency as weighted sum of saliencies? (weighted by score?) --> why? this is similar to scorecam
 co-saliency
 - ablation?
 - self-saliency for vgg16 and resnet50
######################################################################
######################################################################
RECHECK:
save  igos final saliency and then use this as in initializer for mulitthresh_saliency. "who runs it?" the visualizer should run it
---------------------------------------------------------------------
create graphs for (12 graphs):
     deletion & insertion (ig,gradcam,multi, scorecam):
            resnet8,vgg16:
                cifar,mnist,cifar-10

---------------------------------------------------------------------
runallimagenetformultipaper:
    runtorchray run_vast_imagenet_vgg16.sh
    runtorchray run_vast_imagenet_resnet50.sh
---------------------------------------------------------------------
LATER
- cosaliency save and cosaliency panel
- staggered and "both" mode
- continue and use_landataloader
