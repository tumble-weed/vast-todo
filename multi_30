
- run gradient and guided again (runallsmaller, summarize_all_deletion, plotalldeletion)
- run road metric (summarize all road, out filename, plot )
#======================================================
- see results of imagenet-5000 on game_type both
    both seems to give diffuse results as opposed to insertion, which gives sharper results. 
        issue with implementation or loss convergence?
- faster convergence of distillation when using saliency? (compare yours with gradcam and maybe guided backprop)
    - run the knowledge-distillation-pytorch code
    - check how to create a curriculum
        . could be the starting mask where the object is just detected.
            . need a paired data loader that combines the masks and image
                . then also load the deletion data. use the percentage where the class is maximum?
<<EXPERIMENT/CODE>>
- show self saliency comparion with elp:
    PYTHON look at elp code to add the feature layer. --> you can show it with a single area that doesnt change at all ( for imagenet)
        vimelp
        get the results out and save it with your chosen folder
        run_self_saliency
- see both sided imagenet-5000 on the 2 network
    seems a little more blurred out...
- ABLATION number of masks?
    add inner parser arguments
    run on cifar-10,cifar-100,mnist with 40,10 masks
    ......................................................
    - summarize rise
        summarize... in vimtmpalias
        python torchray/helpers/summary2.py --start --method rise_use_compiled_model --dataset voc_2007 --arch vgg16
    - run all methods on imagenet:
        scorecam, groupcam, grad_cam, elp, igospp, multi !guided-Ig
            how do you want to run this, using genrunscript? yeah wecan create genrunscripts for these
                cdrunjson, cp file, genrunscript, cdrunscript ; runtorchray 

    - add hash of the saliencies to the results
    CHATGPT, ERC: howto get hash of a numpy array in python 
<<READ/BROWSER>>
gradient is still the same as guided backprop. why?
    it is different for resnet 50 in elp paper. so should be different for us as well. its odd it 
    https://www.codingninjas.com/studio/library/guided-backpropagation
    https://arxiv.org/abs/1412.6806
    
    run readpkl on guided and grad which have the same number in the table. compare what the saliencies look like:
        errors could be in arguments to saliency,running saliency, saving results, calculating metric, saving metric, running collect, making json from collect
Guided IG
- relation to "Xrai: region importance" and guided backprop
<<TIKZ>>
- evolution of the masks along side the concavity graph? TIKZ, ERC
- convert the graphs from single line to 2 lines LATEX ERC
- use tikz to recreate diagrams TIKZ,ERC
    the arrangement of the masks of ig vs multi
    the qualitative results
<<LATEX>>
- fix small dataset table to fit into area LATEX, ERC
- add accuracy of small networks to the headings in the table? LATEX,ERC
- argmin LATEX,ERC
- overlay concave graph beside text
- why are the references not loading LATEX ERC
<<DIAGNOSE>>
- mask sharpness as a function of the threshold ( should be hump like as well i believe )
    - should we reintroduce the sharpness loss?
- automatic object sizes by finding peak of concave approximation?
    - try this without the approximation? 
a why does it fail with mnist insertion
- better example for a concave graph
- better example for igos vs multi masking ( more detailed i think)
    make the links between images from folder to the paper folder
<<<WRITE>>>
- title
Approach
    - PPR: softmax operator details?
        psuedocode/python
    - PPR: softmax window, kernel size, blurring sigma
    - mention no auxiliary loss in aprroach
        PPR: approach
    - formalize compositional paths etc. create diagram for those
        WRITE
# NOT DOING
- figure igos?
#========================================================
# RECHECK
- captions
- locations of images
- typos, figure captions again, look at figures
- spaces under equations
- lots of repetition involving insertion game
- margin of the deletion table
- approach is lucid?
- masking operator
PPR how tofind the threshold
#======================================================== 
# MAYBE
- qualitative add green borderfor MTS
#======================================================== 
# DONE
- cnn utils fixed drop out mask
    PYTHON replace Dropout with FixedDropout. it has a sample_mask,unset mask setting. in eval it keeps this mask. in train it keeps sampling masks.
- gradcam on compiled model (torchray)
    . currently  backward "second time" error

- imagenet-both failed due to syntax error.
    change the run_json

- some more lines in applying the mask ( blur levels)
- reference for cifar-resnet implementation
- run cosaliency on an image and its flip
mention difference between deletion game during eval and opt
- conclusion
- mask operator as Mask
- fig:enter-label
- self-saliency iamges + section
- change table to resnet | vgg
- mention MTS
- remove mention of deletion
- deletion game reference
a,b,c,d in figures
multithresholded saliency to multi-thresholded
masking comparison example is bad
tma t-summarizedeletion
    summarize road all multi
    plotallroaddeletion
- MTS (ours)
- run road on all multi methods
- references
- table names
- MST to MTS
- restructure masking figure
- get names of layers from undederstanding...sanity check
fc8 fc7 fc6
- plot all thicker lines, 
    larger font sizes
    dont draw axis, 
    background color

- make images for the paper:
    masking
- push multi paper to github and then pull into overleaf
    graphs + legend
    comparison on imagenet
        . local cdpaper..
        . get classnames
        . how many? (3 or 4?)
        soup bowl: 809
        carton:478
        abacus 398
        cradle 516
        pitcher 725
        PICKUP TRUCK 717
- find the accuracies of the networks involved collect deletion?
    validate ...?
        workonvalidatevgg16
        workonvalidateresnet8
        /root/bigfiles/other/metrics-torchray/resnet8_performance
        /root/bigfiles/other/metrics-torchray/vgg16_performance
- make table in the paper
    summarize_all_deletion_smaller
    /root/evaluate-saliency-4/elp_with_scales/torchray/helpers/summarize_deletion.py

#======================================================== 
RUN JUST MULTI
 cdelp; python -m ipdb -c c examples/attribution_benchmark.py --arch vgg16 --dataset cifar-10 --save_detailed_results true --metrics deletion_game $continue_ --use_landataloader false --method multithresh_saliency --window_size 11 --save_results false
- erc upwork
workoncomparemasking
- instead of imagenet-5000 mention imagenet
- the figures for the paper
vim /root/bigfiles/other/metrics-torchray/where_elp_gp_beter_anchor_extremal_perturbation_with_simple_scale_and_crop_with_gp_gp_y_modelog_prob_gp_ncrops1100_gp_sample1_freq1_arch_vgg16_imroots_and_class_ids
# guided resnet8 cifar-10
# cifar-10-guided_backprop-resnet8
  0%|                                                                                                                 | 0/10000 [00:00<?, ?it/s]
- run just insertion
cdelp; python examples/attribution_benchmark.py --arch vgg16 --dataset cifar-10 --save_detailed_results true --metrics deletion_game $continue_ --use_landataloader true --method multithresh_saliency --window_size 3
 - just insertion game?
 - plotdeletion
 - summarize all deletion for multithresh saliency:
    methods=multithresh_saliency summarize_all_deletion_small
 - DATASET=mnist summarize_all_deletion
 - DATASET=cifar-10 IGNORE_METHOD=multithresh_saliency summarize_all_deletion
 - which image to run self saliency on 
 - self saliency panel: add imroot to savename
 - jet map without matplotlib axis for saving in saver
 - lr might be too high for self saliency on lower layers
 - vimtmpalias visualize get images using pointing game ( cherry pick )
 - vimtmpalias visualize qualitative for vgg16 and resnet50
 - visualize script in multithresh_saliency schedule of a randomly initialized mask vs a fully optimized one.
 - measure the mask area across images? -- why, this is not equivalent to elp area .. to show that elp's fixed area is not the way to go
 - collect results of all deletion scores ( summarize deletion? \& collect deletion)
---------------------------------------------------------------------
run in tmux
run multi imagenet  resnet50
IGNORE_METHOD=multithresh_saliency runallsmaller vgg16 mnist
run smaller:
    vgg16:
        cifar-10:
            multi
        cifar-100:
            guided
            grad_cam
            multi
        mnist:
            multi
     resnet8:
        cifar-10:
        cifar-100:
            multi
        mnist:
            multi
............................................         
        mnist:
            gradient
            guided
            grad_cam
            integrated
        cifar-10:
             gradient
            guided
            grad_cam
            integrated
         cifar-100:
             gradient
            integrated
      

######################################################################
######################################################################
DOING
- DROPOUT run for 3 dropouts on each layer
    run across the layers
---------------------------------------------------------------------
finish runs for all cifar stuff
t-smaller
runallsmaller
######################################################################
######################################################################
DONE:
 - the max point seems to be on the top left corner
 - gradcam doesnt seem to have saliency
 tmux sessions:
    - smaller: mnist resnet8
    - ?: c100 resnet8
    x smaller2: cifar-100 vgg16
    - smaller-vgg16 mnist vgg16
    - smaller-vgg16-c10 c10 vgg16
    - smaller-vgg16-c100 c100 vgg16

 - run in another vast instance:
    fix the issues with the vast-utils install
    setup an alias
    add money
    setup_instance
    run the program
 - see the ratios in collect

 cdrunjson &&  cp run_imagenet_vgg16.json run_smaller_vgg16.json && vim run_smaller_vgg16.json && genrunscript run_smaller_vgg16.json
 - check_git
 - check_rclone
 - save the ratios in summarize_deletion
Imagenet on competing is done i think
we should be running pointing on all the imagenet runs
---------------------------------------------------------------------
runallsmallervgg16:
    type expand alias to another variable and run
        in tmux
runallsmallerresnet8:
    in tmux
---------------------------------------------------------------------
visualize for multi paper?
    visualize the trajectory of the images ... 
    look at vimmulti (type vimmulti)
    look at how elp_massking is used and how the areas have been used 
    vim -O $multi -O $comparemasking
check n_done for imagenet vgg16,resnet50 
- which methods ( copy from vimrunjson run_imagenet_vgg16.json)
- loop overmethods and print
- print out the methodnames



NOT DOING
 - block diagram
 - final saliency as weighted sum of saliencies? (weighted by score?) --> why? this is similar to scorecam
 co-saliency
 - ablation?
 - self-saliency for vgg16 and resnet50
######################################################################
######################################################################
RECHECK:
save  igos final saliency and then use this as in initializer for mulitthresh_saliency. "who runs it?" the visualizer should run it
---------------------------------------------------------------------
create graphs for (12 graphs):
     deletion & insertion (ig,gradcam,multi, scorecam):
            resnet8,vgg16:
                cifar,mnist,cifar-10

---------------------------------------------------------------------
runallimagenetformultipaper:
    runtorchray run_vast_imagenet_vgg16.sh
    runtorchray run_vast_imagenet_resnet50.sh
---------------------------------------------------------------------
LATER
- cosaliency save and cosaliency panel
- staggered and "both" mode
- continue and use_landataloader
